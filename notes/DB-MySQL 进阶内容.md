# 分布式

## 分库分表

**划分方式**

分库分表有垂直切分和水平切分两种。
① 垂直切分：即将表按照 <u>功能模块、关系密切程度</u> 划分出来，部署到不同的库上。例如，我们会建立定义数据库workDB、商品数据库payDB、用户数据库userDB、日志数据库logDB等，分别用于存储项目数据定义表、商品定义表、用户数据表、日志数据表等。
② 水平切分：当一个表中的数据量过大时，我们可以把该表的数据按照某种规则，例如userID散列，进行划分，然后  <u>存储到多个结构相同的表，和不同的库上</u>  。例如，我们的userDB中的用户数据表中，每一个表的数据量都很大，就可以把userDB切分为结构相同的多个userDB：part0DB、part1DB等，再将userDB上的用户数据表userTable，切分为很多userTable：userTable0、userTable1等，然后将这些表按照一定的规则存储到多个userDB上。



**两种划分方式的选择**

应该使用哪一种方式来实施数据库分库分表，这要看数据库中数据量的瓶颈所在，并综合项目的业务类型进行考虑。
如果数据库是因为表太多而造成海量数据，并且项目的各项[业务逻辑](https://www.baidu.com/s?wd=%E4%B8%9A%E5%8A%A1%E9%80%BB%E8%BE%91&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1Yvnjm1m10dn1RLP1RvmvFh0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EnH0YPWDsnHbznHf1PWmsnjf4rf)划分清晰、低耦合，那么规则简单明了、容易实施的垂直切分必是首选。
而如果数据库中的表并不多，但单表的数据量很大、或数据热度很高，这种情况之下就应该选择水平切分，水平切分比垂直切分要复杂一些，它将原本逻辑上属于一体的数据进行了物理分割，除了在分割时要对分割的粒度做好评估，考虑数据平均和负载平均，后期也将对项目人员及应用程序产生额外的数据管理负担。
在现实项目中，往往是这两种情况兼而有之，这就需要做出权衡，甚至既需要垂直切分，又需要水平切分。我们的游戏项目便综合使用了垂直与水平切分，我们首先对数据库进行垂直切分，然后，再针对一部分表，通常是用户数据表，进行水平切分。



TH: 根据门店号控制



**划分实现效果**

（1） 单库多表 

   随着用户数量的增加，user 表的数据量会越来越大，当数据量达到一定程度的时候对 user 表的查询会渐渐的变慢，从而影响整个DB的性能。如果使用 mysql, 还有一个更严重的问题是，当需要添加一列的时候，mysql会锁表，期间所有的读写操作只能等待。 
 可以将user进行水平的切分，产生两个表结构完全一样的user_0000,user_0001等表，user_0000 + user_0001 + …的数据刚好是一份完整的数据。 



（2） 多库多表 

随着数据量增加也许单台DB的存储空间不够，随着查询量的增加单台数据库服务器已经没办法支撑。这个时候可以再对数据库进行水平区分。 

分库分表规则举例：

   通过分库分表规则查找到对应的表和库的过程。如分库分表的规则是user_id除以4的方式，当用户新注册了一个账号，账号id的123,我们可以通过id 除以4的方式确定此账号应该保存到User_0003表中。当用户123登录的时候，我们通过123 除以4后确定记录在User_0003中。



数据库分片常见方案

- 客户端代理： 分⽚逻辑在应⽤端，封装在jar包中，通过修改或者封装JDBC层来实现。 当当⽹的 Sharding-JDBC 、阿⾥的TDDL是两种⽐较常⽤的实现。 

- 中间件代理： 在应⽤和数据中间加了⼀个代理层。分⽚逻辑统⼀维护在中间件服务中。 我们现 在谈的 Mycat 、360的Atlas、⽹易的DDB等等都是这种架构的实现。



### ID

(1) UUID：不适合作为主键，因为太⻓了，并且⽆序不可读，查询效率低。⽐较适合⽤于⽣成唯⼀的 名字的标示⽐如⽂件的名字。 

(2) 数据库⾃增 id : 两台数据库分别设置不同步⻓，⽣成不重复ID的策略来实现⾼可⽤。这种⽅式 ⽣成的 id 有序，但是需要独⽴部署数据库实例，成本⾼，还会有性能瓶颈。

(3) 利⽤ redis ⽣成 id : 性能⽐较好，灵活⽅便，不依赖于数据库。但是，引⼊了新的组件造成 系统更加复杂，可⽤性降低，编码更加复杂，增加了系统成本。 

(4) Twitter的snowflake算法 ： 

(5) 美团的Leaf分布式ID⽣成系统 ：Leaf 是美团开源的分布式ID⽣成器，能保证全局唯⼀性、趋势 递增、单调递增、信息安全。



### 分区表

> 一般使用较少...



## 读写分离

// TODO 读写分离的流程图

主库的

从库的 IO 线程： 负责从主库的 binlog 读取过来

从库的 redolog： 重做日志，用于数据恢复使用

从库的 SQL 线程？:  根据 redolog 恢复数据





 在实际的应用中，绝大部分情况都是读远大于写。Mysql提供了读写分离的机制，所有的写操作都必须对应到Master，读操作可以在Master和Slave机器上进行，Slave与Master的结构完全一样，一个Master可以有多个Slave,甚至Slave下还可以挂Slave,通过此方式可以有效的提高DB集群的每秒查询率. 

  所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。 
 此外，可以看出Master是集群的瓶颈，当写操作过多，会严重影响到Master的稳定性，如果Master挂掉，整个集群都将不能正常工作。 
 所以，1. 当读压力很大的时候，可以考虑添加Slave机器的分式解决，但是当Slave机器达到一定的数量就得考虑分库了。 2. 当写压力很大的时候，就必须得进行分库操作。 





# 复制

> 通过 MySQL 服务层的 binlog 实现



## 基于日志点的复制





## 基于 GTLD 复制

> MySQL 5.6 之后提供，5.7 之后较为完善





# 监控

命令行监控



一致性的稳定性



默认情况下 MySQL 的并发为 100， prod 可以调节的更大







